# -*- coding: utf-8 -*-
"""MRISegmentationProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16lDEQ1Zxqc3CrlC0fc_EW5leoXd9KNzy
"""

!nvidia-smi

!pip install tensorflow torch numpy matplotlib nibabel

from google.colab import drive
drive.mount('/content/drive')

base_path = "/content/drive/MyDrive/archive/BraTS2020_training_data/content/data/"

import h5py
import os

sample_file_path = os.path.join(base_path, "volume_351_slice_64.h5")  # Or any other .h5 file

image_data = None
mask_data = None

try:
    with h5py.File(sample_file_path, 'r') as hf:
        print("Keys in h5 file:", list(hf.keys()))  # Print the keys

        image_data = hf['image'][:]  # Read image data
        mask_data = hf['mask'][:]    # Read mask data

        print("Image data shape:", image_data.shape)
        print("Mask data shape:", mask_data.shape)

except FileNotFoundError:
    print(f"Error: File not found: {sample_file_path}")

# You can now use image_data and mask_data outside the try block (if they were read)
if image_data is not None:
    # Do something with image_data
    pass

print("Image data shape:", image_data.shape)

import matplotlib.pyplot as plt

# Assuming image_data has shape (height, width, channels)
channel_titles = ["T1-weighted", "T2-weighted", "FLAIR", "T1-weighted with contrast"]

for channel in range(image_data.shape[2]):
    plt.imshow(image_data[:, :, channel], cmap="gray")
    plt.title(channel_titles[channel])  # Use the channel title from the list
    plt.show()

plt.imshow(mask_data, cmap="jet", alpha=0.5)
plt.title("Segmentation Mask")
plt.show()

import os
import random
import h5py
import numpy as np

base_path = "/content/drive/MyDrive/archive/BraTS2020_training_data/content/data/"

tumor_files = []  # List to store files with tumor presence
sample_size = 1000 #Adjust sample size as needed

all_files = [f for f in os.listdir(base_path) if f.endswith(".h5")]

sampled_files = random.sample(all_files, min(sample_size, len(all_files)))

for file_name in sampled_files:
    file_path = os.path.join(base_path, file_name)

    try:
        with h5py.File(file_path, 'r') as hf:
            mask_data = hf['mask'][:]

        # Check for non-zero mask values (tumor presence)
        unique_mask_values = np.unique(mask_data)
        if len(unique_mask_values) > 1:  # More than just background
            tumor_files.append(file_name)
            print(f"Tumor found in: {file_name}, unique mask values: {unique_mask_values}")
        else:
            print(f"No tumor in: {file_name}")

    except Exception as e:
        print(f"An error occurred: {e}")

print("\nFiles with potential tumor regions:")
print(tumor_files)
print(f"\n{len(tumor_files)} files out of {len(sampled_files)} files contain tumors.")

tumor_volumes = []
for file_name in tumor_files:
    if 'volume_' in file_name:
        volume_id = file_name.split('volume_')[1].split('_slice_')[0]
        if volume_id not in tumor_volumes:
            tumor_volumes.append(volume_id)

print(tumor_volumes)

import os

file_path = "/content/drive/MyDrive/archive/BraTS2020_training_data/content/data/volume_128_slice_155.h5"
directory = os.path.dirname(file_path)

if os.path.exists(directory):
    print(f"Files in directory '{directory}':")
    for filename in os.listdir(directory):
        print(filename)
else:
    print(f"Directory '{directory}' does not exist.")

import h5py
file_path = "/content/drive/MyDrive/archive/BraTS2020_training_data/content/data/volume_1_slice_0.h5"

with h5py.File(file_path, 'r') as hf:
    print("Keys in the .h5 file:", list(hf.keys()))

import h5py
import os
import numpy as np

data_dir = '/content/drive/MyDrive/archive/BraTS2020_training_data/content/data/'  # Correct data directory
selected_volume_id = '1'  # Choose a volume ID

#Data Loading
loaded_data = {}

for file_name in os.listdir(data_dir):
    if file_name.endswith('.h5') and f'volume_{selected_volume_id}_' in file_name:
        file_path = os.path.join(data_dir, file_name)
        with h5py.File(file_path, 'r') as hf:
            mri_data = np.array(hf['image'])  # Use 'image' key
            seg_mask = np.array(hf['mask'])   # Use 'mask' key
            loaded_data.setdefault(selected_volume_id, {'image': [], 'mask': []})
            loaded_data[selected_volume_id]['image'].append(mri_data)
            loaded_data[selected_volume_id]['mask'].append(seg_mask)

#Convert the lists to numpy arrays.
for volume_no in loaded_data:
    loaded_data[volume_no]['image'] = np.array(loaded_data[volume_no]['image'])
    loaded_data[volume_no]['mask'] = np.array(loaded_data[volume_no]['mask'])

def reconstruct_3d_volumes(loaded_data):
    reconstructed_volumes = {}
    for volume_id, data in loaded_data.items():
        z_dim = data['image'].shape[0]
        y_dim = data['image'].shape[1]
        x_dim = data['image'].shape[2]

        reconstructed_volumes[volume_id] = {
            'image': np.zeros((z_dim, y_dim, x_dim, data['image'].shape[3])),
            'mask': np.zeros((z_dim, y_dim, x_dim))
        }

        for i in range(z_dim):
            reconstructed_volumes[volume_id]['image'][i] = data['image'][i]
            reconstructed_volumes[volume_id]['mask'][i] = data['mask'][i][:,:,0] # Take the first channel of the mask.

    return reconstructed_volumes

reconstructed_data = reconstruct_3d_volumes(loaded_data)

print(reconstructed_data[selected_volume_id]['image'].shape)
print(reconstructed_data[selected_volume_id]['mask'].shape)

import numpy as np

#Preprocessing
def preprocess_volume(reconstructed_data):
    """
    Normalizes the MRI data using z-score normalization.

    Args:
        reconstructed_data: A dictionary containing the reconstructed MRI data and mask.

    Returns:
        A dictionary containing the normalized MRI data and the original mask.
    """

    mri_data = reconstructed_data['1']['image']
    mask_data = reconstructed_data['1']['mask']

    # Z-score normalization for each channel of the MRI data.
    normalized_mri_data = np.zeros_like(mri_data, dtype=np.float32)
    for channel in range(mri_data.shape[-1]):  # Iterate over channels
        channel_data = mri_data[..., channel]
        mean = np.mean(channel_data)
        std = np.std(channel_data)
        if std != 0:  # Avoid division by zero
            normalized_mri_data[..., channel] = (channel_data - mean) / std
        else:
            normalized_mri_data[..., channel] = channel_data  # Keep original if std is 0

    return {'image': normalized_mri_data, 'mask': mask_data}

#Preprocess the data.
preprocessed_data = preprocess_volume(reconstructed_data)

print(preprocessed_data['image'].shape)
print(preprocessed_data['mask'].shape)
print(f'MRI data mean: {np.mean(preprocessed_data["image"])}')
print(f'MRI data std: {np.std(preprocessed_data["image"])}')

# Simplified Model before Trying Full Model

import tensorflow as tf
from tensorflow.keras import layers

def build_3d_unet(input_shape):
    inputs = layers.Input(input_shape)

    # Encoder (Downsampling)
    conv1 = layers.Conv3D(32, 3, activation='relu', padding='same')(inputs)
    conv1 = layers.Conv3D(32, 3, activation='relu', padding='same')(conv1)
    pool1 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)

    conv2 = layers.Conv3D(64, 3, activation='relu', padding='same')(pool1)
    conv2 = layers.Conv3D(64, 3, activation='relu', padding='same')(conv2)
    pool2 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)

    # Bottleneck
    conv3 = layers.Conv3D(128, 3, activation='relu', padding='same')(pool2)
    conv3 = layers.Conv3D(128, 3, activation='relu', padding='same')(conv3)

    # Decoder (Upsampling)
    up4 = layers.Conv3DTranspose(64, 2, strides=(2, 2, 2), padding='same')(conv3)
    concat4 = layers.concatenate([up4, conv2], axis=-1)
    conv4 = layers.Conv3D(64, 3, activation='relu', padding='same')(concat4)
    conv4 = layers.Conv3D(64, 3, activation='relu', padding='same')(conv4)

    up5 = layers.Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='same')(conv4)
    concat5 = layers.concatenate([up5, conv1], axis=-1)
    conv5 = layers.Conv3D(32, 3, activation='relu', padding='same')(concat5)
    conv5 = layers.Conv3D(32, 3, activation='relu', padding='same')(conv5)

    # Output layer
    outputs = layers.Conv3D(1, 1, activation='sigmoid')(conv5)  # 1 channel for segmentation mask

    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

# Build the model
input_shape = (152, 240, 240, 4)  # Adjusted input shape
model = build_3d_unet(input_shape)

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy') #Example loss.

#Print model summary.
model.summary()

# Advanced Model

import tensorflow as tf
from tensorflow.keras import layers

def build_advanced_3d_unet(input_shape):
    inputs = layers.Input(input_shape)

    # Encoder
    conv1 = layers.Conv3D(32, 3, activation='relu', padding='same')(inputs)
    conv1 = layers.Conv3D(32, 3, activation='relu', padding='same')(conv1)

    up_conv1 = layers.Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='same')(conv1) #upsample conv1
    print(f'up_conv1 shape: {up_conv1.shape}')

    pool1 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)
    print(f"pool1 shape: {pool1.shape}")

    conv2 = layers.Conv3D(64, 3, activation='relu', padding='same')(pool1)
    conv2 = layers.Conv3D(64, 3, activation='relu', padding='same')(conv2)
    pool2 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)
    print(f"pool2 shape: {pool2.shape}")

    up_conv2 = layers.Conv3DTranspose(64, 2, strides=(2, 2, 2), padding='same')(conv2)
    print(f'up_conv2 shape: {up_conv2.shape}')

    conv3 = layers.Conv3D(128, 3, activation='relu', padding='same')(pool2)
    conv3 = layers.Conv3D(128, 3, activation='relu', padding='same')(conv3)
    pool3 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv3)
    print(f"pool3 shape: {pool3.shape}")

    up_conv3 = layers.Conv3DTranspose(128, 2, strides=(2, 2, 2), padding='same')(conv3)
    print(f'up_conv3 shape: {up_conv3.shape}')

    conv4 = layers.Conv3D(256, 3, activation='relu', padding='same')(pool3)
    conv4 = layers.Conv3D(256, 3, activation='relu', padding='same')(conv4)
    drop4 = layers.Dropout(0.5)(conv4)
    print(f"drop4 shape: {drop4.shape}")

    up_drop4 = layers.Conv3DTranspose(256, 2, strides=(2, 2, 2), padding='same')(drop4)
    print(f'up_drop4 shape: {up_drop4.shape}')

    # Bottleneck
    conv5 = layers.Conv3D(512, 3, activation='relu', padding='same')(drop4)
    conv5 = layers.Conv3D(512, 3, activation='relu', padding='same')(conv5)
    drop5 = layers.Dropout(0.5)(conv5)
    print(f"drop5 shape: {drop5.shape}")

    # Decoder
    up6 = layers.Conv3DTranspose(256, 2, strides=(2, 2, 2), padding='same')(drop5)
    print(f"up6 shape: {up6.shape}")
    conv6 = layers.Conv3D(256, 3, activation='relu', padding='same')(up6)
    print(f"conv6 shape: {conv6.shape}")
    merge6 = layers.concatenate([conv6, up_drop4], axis=-1)
    print(f"merge6 shape: {merge6.shape}")
    conv6 = layers.Conv3D(256, 3, activation='relu', padding='same')(merge6)
    conv6 = layers.Conv3D(256, 3, activation='relu', padding='same')(conv6)

    up7 = layers.Conv3DTranspose(128, 2, strides=(2, 2, 2), padding='same')(conv6)
    print(f"up7 shape: {up7.shape}")
    conv7 = layers.Conv3D(128, 3, activation='relu', padding='same')(up7)
    print(f"conv7 shape: {conv7.shape}")
    merge7 = layers.concatenate([conv7, up_conv3], axis=-1)
    print(f"merge7 shape: {merge7.shape}")
    conv7 = layers.Conv3D(128, 3, activation='relu', padding='same')(merge7)
    conv7 = layers.Conv3D(128, 3, activation='relu', padding='same')(conv7)

    up8 = layers.Conv3DTranspose(64, 2, strides=(2, 2, 2), padding='same')(conv7)
    print(f"up8 shape: {up8.shape}")
    conv8 = layers.Conv3D(64, 3, activation='relu', padding='same')(up8)
    print(f"conv8 shape: {conv8.shape}")
    merge8 = layers.concatenate([conv8, up_conv2], axis=-1)
    print(f"merge8 shape: {merge8.shape}")
    conv8 = layers.Conv3D(64, 3, activation='relu', padding='same')(merge8)
    conv8 = layers.Conv3D(64, 3, activation='relu', padding='same')(conv8)

    up9 = layers.Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='same')(conv8)
    print(f"up9 shape: {up9.shape}")
    conv9 = layers.Conv3D(32, 3, activation='relu', padding='same')(up9)
    print(f"conv9 shape: {conv9.shape}")
    merge9 = layers.concatenate([conv9, up_conv1], axis=-1)
    print(f"merge9 shape: {merge9.shape}")
    conv9 = layers.Conv3D(32, 3, activation='relu', padding='same')(merge9)
    conv9 = layers.Conv3D(32, 3, activation='relu', padding='same')(conv9)

    conv10 = layers.Conv3D(1, 1, activation='sigmoid')(conv9)

    model = tf.keras.Model(inputs=inputs, outputs=conv10)
    return model

# Example usage
input_shape = (152, 240, 240, 4)
model = build_advanced_3d_unet(input_shape)
model.compile(optimizer='adam', loss='binary_crossentropy')
model.summary()

import tensorflow as tf
from tensorflow.keras import layers

def build_advanced_3d_unet(input_shape):
    inputs = layers.Input(input_shape)

    # Encoder
    conv1 = layers.Conv3D(32, 3, activation='relu', padding='same')(inputs)
    conv1 = layers.Conv3D(32, 3, activation='relu', padding='same')(conv1)

    up_conv1 = layers.Conv3DTranspose(32, 2, strides=(1, 1, 1), padding='same')(conv1) #Change Strides.
    print(f'up_conv1 shape: {up_conv1.shape}')

    pool1 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)
    print(f"pool1 shape: {pool1.shape}")

    conv2 = layers.Conv3D(64, 3, activation='relu', padding='same')(pool1)
    conv2 = layers.Conv3D(64, 3, activation='relu', padding='same')(conv2)
    pool2 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)
    print(f"pool2 shape: {pool2.shape}")

    up_conv2 = layers.Conv3DTranspose(64, 2, strides=(2, 2, 2), padding='same')(conv2)
    print(f'up_conv2 shape: {up_conv2.shape}')

    conv3 = layers.Conv3D(128, 3, activation='relu', padding='same')(pool2)
    conv3 = layers.Conv3D(128, 3, activation='relu', padding='same')(conv3)
    pool3 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv3)
    print(f"pool3 shape: {pool3.shape}")

    up_conv3 = layers.Conv3DTranspose(128, 2, strides=(2, 2, 2), padding='same')(conv3)
    print(f'up_conv3 shape: {up_conv3.shape}')

    conv4 = layers.Conv3D(256, 3, activation='relu', padding='same')(pool3)
    conv4 = layers.Conv3D(256, 3, activation='relu', padding='same')(conv4)
    drop4 = layers.Dropout(0.5)(conv4)
    print(f"drop4 shape: {drop4.shape}")

    up_drop4 = layers.Conv3DTranspose(256, 2, strides=(2, 2, 2), padding='same')(drop4)
    print(f'up_drop4 shape: {up_drop4.shape}')

    # Bottleneck
    conv5 = layers.Conv3D(512, 3, activation='relu', padding='same')(drop4)
    conv5 = layers.Conv3D(512, 3, activation='relu', padding='same')(conv5)
    drop5 = layers.Dropout(0.5)(conv5)
    print(f"drop5 shape: {drop5.shape}")

    # Decoder
    up6 = layers.Conv3DTranspose(256, 2, strides=(2, 2, 2), padding='same')(drop5)
    print(f"up6 shape: {up6.shape}")
    conv6 = layers.Conv3D(256, 3, activation='relu', padding='same')(up6)
    print(f"conv6 shape: {conv6.shape}")
    merge6 = layers.concatenate([conv6, up_drop4], axis=-1)
    print(f"merge6 shape: {merge6.shape}")
    conv6 = layers.Conv3D(256, 3, activation='relu', padding='same')(merge6)
    conv6 = layers.Conv3D(256, 3, activation='relu', padding='same')(conv6)

    up7 = layers.Conv3DTranspose(128, 2, strides=(2, 2, 2), padding='same')(conv6)
    print(f"up7 shape: {up7.shape}")
    conv7 = layers.Conv3D(128, 3, activation='relu', padding='same')(up7)
    print(f"conv7 shape: {conv7.shape}")
    merge7 = layers.concatenate([conv7, up_conv3], axis=-1)
    print(f"merge7 shape: {merge7.shape}")
    conv7 = layers.Conv3D(128, 3, activation='relu', padding='same')(merge7)
    conv7 = layers.Conv3D(128, 3, activation='relu', padding='same')(conv7)

    up8 = layers.Conv3DTranspose(64, 2, strides=(2, 2, 2), padding='same')(conv7)
    print(f"up8 shape: {up8.shape}")
    conv8 = layers.Conv3D(64, 3, activation='relu', padding='same')(up8)
    print(f"conv8 shape: {conv8.shape}")
    merge8 = layers.concatenate([conv8, up_conv2], axis=-1)
    print(f"merge8 shape: {merge8.shape}")
    conv8 = layers.Conv3D(64, 3, activation='relu', padding='same')(merge8)
    conv8 = layers.Conv3D(64, 3, activation='relu', padding='same')(conv8)

    up9 = layers.Conv3DTranspose(32, 2, strides=(1, 1, 1), padding='same')(conv8)
    print(f"up9 shape: {up9.shape}")
    conv9 = layers.Conv3D(32, 3, activation='relu', padding='same')(up9)
    print(f"conv9 shape: {conv9.shape}")
    merge9 = layers.concatenate([conv9, up_conv1], axis=-1)
    print(f"merge9 shape: {merge9.shape}")
    conv9 = layers.Conv3D(32, 3, activation='relu', padding='same')(merge9)
    conv9 = layers.Conv3D(32, 3, activation='relu', padding='same')(conv9)

    conv10 = layers.Conv3D(1, 1, activation='sigmoid')(conv9)

    model = tf.keras.Model(inputs=inputs, outputs=conv10)
    return model

# ========== GPU CONFIGURATION ==========
import tensorflow as tf
import numpy as np
import h5py
import os
import random
from tensorflow.keras import layers, Model, backend as K
import matplotlib.pyplot as plt

# Verify GPU availability
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        # Set memory growth to prevent OOM errors
        tf.config.experimental.set_memory_growth(gpus[0], True)
        print(f"GPU detected: {gpus[0]}")
        # Use float32 for maximum compatibility
        tf.keras.mixed_precision.set_global_policy('float32')
    except RuntimeError as e:
        print("GPU configuration error:", e)
else:
    print("No GPU detected, using CPU")

# ========== FIXED DATA GENERATOR ==========
def data_generator(data_dir, volume_ids, patch_size=(64, 64, 64), batch_size=2, validation=False):
    """Generates 3D patches with size validation and error handling."""

    def generator():
        while True:
            batch_images = []
            batch_masks = []
            file_list = [f for f in os.listdir(data_dir)
                        if f.endswith('.h5') and any(f'volume_{vid}_' in f for vid in volume_ids)]

            if not file_list:
                raise ValueError(f"No matching files found in {data_dir}")

            random.shuffle(file_list)

            for file_name in file_list:
                try:
                    with h5py.File(os.path.join(data_dir, file_name), 'r') as hf:
                        image = np.array(hf['image'], dtype=np.float32)
                        mask = np.array(hf['mask'][..., 0], dtype=np.float32)

                        # Skip slices smaller than patch size
                        if any(image.shape[i] < patch_size[i] for i in range(3)):
                            continue

                        # Get patch coordinates
                        if validation:
                            z, y, x = [(s - ps) // 2 for s, ps in zip(image.shape[:3], patch_size)]
                        else:
                            z = random.randint(0, image.shape[0] - patch_size[0])
                            y = random.randint(0, image.shape[1] - patch_size[1])
                            x = random.randint(0, image.shape[2] - patch_size[2])

                        # Extract patches
                        img_patch = image[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]]
                        mask_patch = mask[z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]]

                        # Channel-wise normalization
                        for c in range(4):  # For all 4 MRI channels
                            channel = img_patch[..., c]
                            img_patch[..., c] = (channel - np.mean(channel)) / (np.std(channel) + 1e-8)

                        batch_images.append(img_patch)
                        batch_masks.append(mask_patch[..., np.newaxis])

                        if len(batch_images) == batch_size:
                            yield (tf.convert_to_tensor(np.stack(batch_images),
                                   tf.convert_to_tensor(np.stack(batch_masks)))
                            batch_images = []
                            batch_masks = []

                except Exception as e:
                    print(f"Skipping {file_name}: {str(e)}")
                    continue

    return tf.data.Dataset.from_generator(
        generator,
        output_signature=(
            tf.TensorSpec(shape=(None, *patch_size, 4), dtype=tf.float32),
            tf.TensorSpec(shape=(None, *patch_size, 1), dtype=tf.float32)
        )
    )

# ========== MODEL ARCHITECTURE ==========
def build_3d_unet(input_shape=(64, 64, 64, 4)):
    inputs = layers.Input(input_shape, dtype=tf.float32)

    # Encoder
    def conv_block(x, filters):
        x = layers.Conv3D(filters, 3, activation='relu', padding='same')(x)
        return layers.Conv3D(filters, 3, activation='relu', padding='same')(x)

    conv1 = conv_block(inputs, 32)
    pool1 = layers.MaxPooling3D(2)(conv1)

    conv2 = conv_block(pool1, 64)
    pool2 = layers.MaxPooling3D(2)(conv2)

    conv3 = conv_block(pool2, 128)
    pool3 = layers.MaxPooling3D(2)(conv3)

    # Bottleneck
    conv4 = conv_block(pool3, 256)
    drop4 = layers.Dropout(0.5)(conv4)

    # Decoder
    def upsample_block(x, skip, filters):
        x = layers.Conv3DTranspose(filters, 2, strides=2, padding='same')(x)
        x = layers.concatenate([x, skip])
        return conv_block(x, filters)

    up5 = upsample_block(drop4, conv3, 128)
    up6 = upsample_block(up5, conv2, 64)
    up7 = upsample_block(up6, conv1, 32)

    # Output
    outputs = layers.Conv3D(1, 1, activation='sigmoid', dtype=tf.float32)(up7)

    return Model(inputs=inputs, outputs=outputs)

# ========== TRAINING SETUP ==========
def train_model():
    # Build model
    model = build_3d_unet()
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    # Data setup
    data_dir = '/content/drive/MyDrive/archive/BraTS2020_training_data/content/data/'
    train_volumes = ['1', '2', '3']
    val_volumes = ['4']

    train_ds = data_generator(data_dir, train_volumes, batch_size=2).prefetch(tf.data.AUTOTUNE)
    val_ds = data_generator(data_dir, val_volumes, batch_size=1, validation=True).prefetch(tf.data.AUTOTUNE)

    # Callbacks
    callbacks = [
        tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True),
        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3),
        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)
    ]

    # Train
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=50,
        steps_per_epoch=100,
        validation_steps=20,
        callbacks=callbacks
    )

    return model, history

# ========== EXECUTION ==========
print("Starting training...")
try:
    model, history = train_model()
    print("Training completed successfully!")
except Exception as e:
    print("Training failed:", str(e))